# 线性回归
  - 一元线性回归
  - 多元线性回归

转载 https://blog.csdn.net/maplepiece1999/article/details/103965626

### 一元线性回归

  - 相关关系：相关关系是值变量的数值之间存在这依存关系，即一个变量的数值会随着另一个变量或几个变量的数值变化而呈现出一定的变化规律。
  - 单相关关系是指两个变量之间的关系，分为自变量和因变量，也称为二元变量相关分析；
- 复相关关系是指三个或三个以上变量之间的关系，即一个因变量对两个或两个以上自变量的相关关系，也称多重相关关系；
- 偏相关关系是指在一个因变量与多个自变量相关的情况下，只关心因变量与其中一个自变量的关系，屏蔽其他自变量对因变量的影响。
#### 最小二乘法
- 最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。
#### 拟合优度检测
- 拟合优度（Goodness of Fit）是指回归直线对观测值的拟合程度，是用来测量模型的回归程度好坏的。拟合优度检验是假设检验的一种，用来检测观测数与根据模型计算得到的理论数之间的一种假设检验，以便于判断该假设或模型是否与实际观测数吻合
#### 显著性检验
我们知道，在假设检验中有两类错误：

- 原假设实际为真，但根据样本数据判别为拒绝，此类错误被称为“弃真”错误，即将真的当作假的。
- 原假设实际为假，但根据样本数据判别为接受，此类错误被称为“取伪”错误，即将假的当作真的。
```
通常把第一类错误出现的概率记为α，第二类错误出现的概率记为β。通常只限定犯第一类错误的最大概率α， 不考虑犯第二类错误的概率β。我们把这样的假设检验称为显著性检验，并且称概率α称为显著性水平。
```
#### 回归预测
- 回归分析预测法，是在分析市场现象自变量和因变量之间相关关系的基础上，建立变量之间的回归方程，并将回归方程作为预测模型，根据自变量在预测期的数量变化来预测因变量，关系大多表现为相关关系。
#### 残差分析
- 残差是指观测值与预测值（拟合值）之间的差，即是实际观察值与回归估计值的差。
在回归分析中，测定值与按回归方程预测的值之差，并且残差服从正态分布，通常可以根据分析残差的分布情况来校验模型的合理性

### 多元线性回归
#### 多重共线性
- 在多元线性回归模型经典假设中，其重要假定之一是回归模型的解释变量之间不存在线性关系，也就是说，解释变量X1，X2，……，Xk中的任何一个都不能是其他解释变量的线性组合。如果违背这一假定，即线性回归模型中某一个解释变量与其他解释变量间存在线性关系，就称线性回归模型中存在多重共线性。多重共线性违背了解释变量间不相关的古典假设，将给普通最小二乘法带来严重后果。
#### 变量选择与逐步回归
- 在建立回归模型时，首要问题是如何确定回归自变量，若遗漏了重要的变量，回归方程的效果肯定不会太好，但是当变量过多时，某些变量可能会重叠，某些程度上会增大计算量，回归方程稳定性也差，直接影响到回归方程的使用。

#### 实践
借鉴以下链接学习python实践
https://blog.csdn.net/long636/article/details/104222926


